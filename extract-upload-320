#!/bin/bash

# This script can extract cover from comicbook in .cbz (zip files)
# and upload it to casimages (redim 320)
# Then display casimages url using zenity (+ add [img] BBCODE)

comic="$1"
fullcover=""
ftype=""
cover=""

function get-file-type {
    mimetype=$(file --mime-type -b "${1}")
    case "$mimetype" in
        image/png) ftype="png";;
        image/jpeg) ftype="jpg";;
        *)
            zenity --error --text="Pas le bon format (seulement jpg/jpeg/png)."
            exit 1;;
    esac
}

# Find cover (first jpg)
# echo Before unzip
fullcover=$(unzip -Z1 "$comic" | grep -i '[.]jpe\?g$' | sort | head -n 1) || zenity --error --text="Pas le bon format (seulement jpg/jpeg/png)." || exit 1

# echo "$fullcover"

# unzip cover
unzip  -j "$comic" "$fullcover"

cover=$(basename "$fullcover")

get-file-type "$cover"

# This first GET initialize "cookie"
curl -s -c "$HOME/.casimagecookie" GET https://www.casimages.com/ -H "Accept: application/json" >/dev/null

# Just changing to dim 320 page.
curl -s 'https://www.casimages.com/ajax/s_ano_resize.php?dim=320' \
-H 'Pragma: no-cache' \
-H 'Sec-Fetch-Site: same-origin' \
-H 'DNT: 1' \
-H 'Accept-Encoding: gzip, deflate, br' \
-H 'Accept-Language: fr-FR,fr;q=0.9,en-US;q=0.8,en;q=0.7' \
-H 'User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.75 Safari/537.36' \
-H 'Sec-Fetch-Mode: cors' \
-H 'Accept: text/plain, */*; q=0.01' \
-H 'Cache-Control: no-cache' \
-H 'X-Requested-With: XMLHttpRequest' \
-b "$HOME/.casimagecookie" \
-H 'Connection: keep-alive' \
-H 'Referer: https://www.casimages.com/' --compressed

# Upload the file
img_id=$(curl -s 'https://www.casimages.com/upload_ano_multi.php' \
-H 'User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:69.0) Gecko/20100101 Firefox/69.0' \
-H 'Cache-Control: no-cache' \
-H 'Connection: keep-alive' \
-H 'Pragma: no-cache' \
--form "Filedata=@${cover};type=image/${ftype}" \
-H 'Accept: application/json' \
-H 'X-Requested-With: XMLHttpRequest' \
-H 'Referer: https://www.casimages.com/' \
-H 'Accept-Language: fr-FR,fr;q=0.8,en-US;q=0.5,en;q=0.3' --compressed \
-b "$HOME/.casimagecookie")

# echo "${img_id}"

# Curl the result page and regex to find "Grande" url
# There's two Grande resutls -> x is an array
x=($(curl -s "https://www.casimages.com/codes_ano_multi.php?img=${img_id}" | grep -Po "Grande : .*?value='\\K(.*?)>"))

# delete 2 last characters
url=${x[1]::-2}

# Put result in a textfile
echo "[img]$url[/img]" > "$HOME/urlcasi.txt"

# Display result in zenity
zenity --text-info --title="URL casimages" \
       --width=800 --height=200 --filename="$HOME/urlcasi.txt"

# Clean up
rm "$HOME/urlcasi.txt"
rm "$HOME/.casimagecookie"
rm "$cover"
